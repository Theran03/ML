{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a872b6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CÓDIGO CORRESPONDIENTE AL EXÁMEN #1.\n",
    "#PRESENTADO POR: Andrés Theran y Daniel Ortíz\n",
    "#UNIVERSIDAD DE CÓRDOBA\n",
    "\n",
    "#Paquete  necesario para el código: \n",
    "# pip install notebook scikit-learn numpy\n",
    "\n",
    "#PARTE INICIAL PARA OBTENER INFORMACIÓN DEL CONJUNTO DE DATOS.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Cargar el dataset\n",
    "california = fetch_california_housing()\n",
    "X = california.data\n",
    "y = california.target.reshape(-1, 1) #Para manejar los valores objetivos como un vector columna.\n",
    "feature_names = california.feature_names\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print('Descripción del dataset:')\n",
    "print(california.DESCR[:1500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4884f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocesamiento : normalización de datos y escogencia de entrenamiento (80%) y prueba (20%)\n",
    "\n",
    "#1. Escogemos conjunto de training y conjunto de test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#2. Normalizamos los datos de training y los de test (teniendo en cuenta solo la información estadística del training).\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ebc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Definimos los parámetros.\n",
    "\n",
    "def inicializar_parametros(n_caracteristicas):\n",
    "    \n",
    "    # Pesos aleatorios pequeños\n",
    "    w = np.random.randn(n_caracteristicas, 1) * 0.01\n",
    "        \n",
    "    # Sesgo en cero\n",
    "    b = 0.0\n",
    "    \n",
    "    return w, b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cc2e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la suma ponderada de las caracteristicas con sus pesos para los ejemplos\n",
    "def propagacion_adelante(X, w, b):\n",
    "    z = X @ w + b \n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6af3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de predicción para 5 registros\n",
    "\n",
    "#asignar caracteristicas\n",
    "n_caracteristicas = X_train_scaled.shape[1]\n",
    "\n",
    "#asignar pesos y sesgos.\n",
    "w, b = inicializar_parametros(n_caracteristicas)\n",
    "\n",
    "X_train_exa = X_train_scaled[:5]\n",
    "y_real_exa = y_train[:5]\n",
    "\n",
    "# Predicciones iniciales\n",
    "y_pred_exa = propagacion_adelante(X_train_exa, w, b)\n",
    "\n",
    "print(\"Predicciones iniciales:\")\n",
    "print(y_pred_exa)\n",
    "\n",
    "print(\"\\nValores reales:\")\n",
    "print(y_real_exa)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd88d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Función que calcula la pérdida para este caso de regresión\n",
    "\n",
    "def calcular_perdida(y_pred, y_real):\n",
    "    \n",
    "    m = y_real.shape[0]\n",
    "    \n",
    "    mse = (1/m) * np.sum((y_pred - y_real)**2)\n",
    "    \n",
    "    return mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a09c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la predicción de las viviendas para los parámetros iniciales. (no se ha entrado la red aún)\n",
    "y_pred_t=propagacion_adelante(X_train_scaled,w,b)\n",
    "\n",
    "#Calculamos la pérdida para esta primera predicción\n",
    "mse_i=calcular_perdida(y_pred_t,y_train)\n",
    "print(mse_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03f6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos los gradientes con respecto a los parámetros\n",
    "\n",
    "def calcular_gradientes (X, y_pred,y_real):\n",
    "    m=X.shape[0]\n",
    "\n",
    "    error=y_pred-y_real\n",
    "    \n",
    "    dw=(2/m)*(X.T @ error)\n",
    "    db=(2/m)*np.sum(error)\n",
    "\n",
    "    return dw,db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14866a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos la actualización de parámetros.\n",
    "def actualizar_parametros (w,b,dw,db,learning_rate):\n",
    "    \n",
    "    w= w - learning_rate*dw \n",
    "    b= b - learning_rate*db    \n",
    "\n",
    "    return w,b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de entrenamiento del perceptrón para regresión.\n",
    "def entrenar_perceptron(X_train, y_train, learning_rate, epochs):\n",
    "    n_caracteristicas = X_train_scaled.shape[1]\n",
    "\n",
    "#asignar pesos y sesgos.\n",
    "    w, b = inicializar_parametros(n_caracteristicas)\n",
    "    historial_perdida = []\n",
    "    \n",
    "    for epoca in range(epochs):\n",
    "        \n",
    "        # 1️ Propagación adelante\n",
    "        y_pred = propagacion_adelante(X_train, w, b)\n",
    "        \n",
    "        # 2️ Calcular pérdida\n",
    "        perdida = calcular_perdida(y_pred, y_train)\n",
    "        historial_perdida.append(perdida)\n",
    "        \n",
    "        # 3️ Calcular gradientes\n",
    "        dw, db = calcular_gradientes(X_train, y_pred, y_train)\n",
    "        \n",
    "        # 4️ Actualizar parámetros\n",
    "        w, b = actualizar_parametros(w, b, dw, db, learning_rate)\n",
    "        \n",
    "        if epoca % 100 == 0:\n",
    "            print(f'Época {epoca}, Pérdida: {perdida:.4f}')\n",
    "            print(\"-\"*50)\n",
    "    return w, b, historial_perdida\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125f574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Entrenamos el perceptrón con diferentes tasas de aprendizaje y guardamos los pesos, sesgos e historial de pérdida para cada caso.\n",
    "h4=w4,b4,historial_perdida4=entrenar_perceptron(X_train_scaled,y_train,1.0,1000)\n",
    "h1=w1,b1,historial_perdida1=entrenar_perceptron(X_train_scaled, y_train,0.01,1000)\n",
    "h2=w2,b2,historial_perdida2=entrenar_perceptron(X_train_scaled,y_train,0.1,1000)\n",
    "h3=w3,b3,historial_perdida3=entrenar_perceptron(X_train_scaled,y_train,0.001,1000)\n",
    "print(\"Guardamos los pesos, sesgos e historial de pérdida para cada tasa de aprendizaje.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67644c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Visualizamos la evolución de la pérdida para la tasa de aprendizaje 0.01\n",
    "plt.plot(historial_perdida1)\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.title(\"Evolución de la pérdida\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b3eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparación de la evolución de la pérdida para las diferentes tasas de aprendizaje.\n",
    "plt.figure()\n",
    "plt.plot(historial_perdida4, label=\"lr=1.0\")\n",
    "plt.plot(historial_perdida3, label=\"lr=0.001\")\n",
    "plt.plot(historial_perdida1, label=\"lr=0.01\")\n",
    "plt.plot(historial_perdida2, label=\"lr=0.1\")\n",
    "\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(0,6)\n",
    "plt.title(\"Comparación de tasas de aprendizaje\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el MSE final de entrenamiento para la tasa de aprendizaje 0.01\n",
    "mse_entrenamiento_final = historial_perdida1[-1]\n",
    "print(\"MSE final de entrenamiento:\", mse_entrenamiento_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a54b2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos el MSE en el conjunto de prueba para el conjunto de parámetros entrenados con tasa de aprendizaje 0.01\n",
    "y_test_pred = propagacion_adelante(X_test_scaled, w1, b1)\n",
    "mse_test = calcular_perdida(y_test_pred, y_test)\n",
    "print(\"MSE en conjunto de prueba:\", mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2157432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizamos las predicciones vs los valores reales para el conjunto de prueba.\n",
    "# la  línea roja discontinua representa la situación ideal donde las predicciones coinciden exactamente con los valores reales (y=x).\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.scatter(y_test, y_test_pred, s=10,alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()],\n",
    "         'r--', label='y=x')\n",
    "plt.xlabel(\"Valores reales (y_test)\")\n",
    "plt.ylabel(\"Predicciones\")\n",
    "plt.title(\"Predicciones vs valores reales\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22f5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos el coeficiente de determinación R² para evaluar la calidad de las predicciones.\n",
    "SS_res = np.sum((y_test - y_test_pred)**2)\n",
    "SS_tot = np.sum((y_test - np.mean(y_test))**2)\n",
    "\n",
    "R2 = 1 - (SS_res / SS_tot)\n",
    "\n",
    "print(\"R²:\", R2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
